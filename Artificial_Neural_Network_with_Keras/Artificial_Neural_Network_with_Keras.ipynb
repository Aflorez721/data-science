{
  "cells": [
    {
      "metadata": {
        "_uuid": "f598221755016c3dae2ac6b9c8ef4012a6c9db9f"
      },
      "cell_type": "markdown",
      "source": "[](http://)<font color=\"red\" size=4>What is Artificial Neural Network?</font>\n<br>\nArtifical Neural Networks (ANN) are one of the main tools which are used in machine learning. \"Neural\" part of their name is called as like that because these systems try to learn things like human brain. Replicated networks contains some kind of neurons and these neurons create a network by connecting each other. These networks have capacity of learning, storing and finding out relationships between datas like a human! <br>\nFor example they can learn to identify images that contain cars by analyzing example images. So after learning phase is completed if you ask to algorithm 'Is it a car?' by giving it an image, algorithm can answer your question becuase it identified other cars images and learned how a car looks like. <br>\nNeural Networks has input and output layers like others but most of the cases they also have hidden layers, and usually we can say how 'deep' our algorithm according to number of hidden layers.\n<br>\n<br>\n<br>\n<img src=\"https://icdn5.digitaltrends.com/image/artificial_neural_network_1-791x388.jpg\" width=400/>\n<br>\n<br>\nNow we'll try to use this algorithm with a dataset contains images of 10 different classes of fashion. \n<br>\n<br>\n**CONTENT**\n1. [Information About Data](#1)\n1. [Reading Data](#2)\n1. [ANN with Keras](#3)"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train-images-idx3-ubyte', 'train-labels-idx1-ubyte', 't10k-labels-idx1-ubyte', 'fashion-mnist_train.csv', 't10k-images-idx3-ubyte', 'fashion-mnist_test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a156a3c39bb74ae571501dc65bdc00dcf980e924"
      },
      "cell_type": "markdown",
      "source": "**About Dataset**<a id=1></a><br>\n<br>\nDataset consists a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n    - Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.\n    - Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.\n    - The training and test data sets have 785 columns. The first column consists of the class labels, and represents class of clothing. The rest of the columns contain the pixel-values of the associated image.\n<br>\nEach training and test example is assigned to one of the following labels:\n\n    - 0 T-shirt/top\n    - 1 Trouser\n    - 2 Pullover\n    - 3 Dress\n    - 4 Coat\n    - 5 Sandal\n    - 6 Shirt\n    - 7 Sneaker\n    - 8 Bag\n    - 9 Ankle boot \n\nSince we want binary classification we'll just choose 0 and 1 for our data."
    },
    {
      "metadata": {
        "_uuid": "16f7156c839160f581dfe32b95e42164ea08c482"
      },
      "cell_type": "markdown",
      "source": "**Read Data**<a id=2></a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae9f1b80920b1089b6b7445eec733c0c7061e8a0"
      },
      "cell_type": "code",
      "source": "dfAll = pd.read_csv(\"../input/fashion-mnist_train.csv\")\ndf = dfAll[((dfAll.label == 0) | (dfAll.label == 1))]",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c674a3247e5ff11d389fe4a7d71cc7296e48cc7"
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "    label  pixel1  pixel2    ...     pixel782  pixel783  pixel784\n3       0       0       0    ...            0         0         0\n10      0       0       0    ...            0         0         0\n13      0       0       0    ...            0         0         0\n24      0       0       0    ...            0         0         0\n29      1       0       0    ...            0         0         0\n\n[5 rows x 785 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>pixel10</th>\n      <th>pixel11</th>\n      <th>pixel12</th>\n      <th>pixel13</th>\n      <th>pixel14</th>\n      <th>pixel15</th>\n      <th>pixel16</th>\n      <th>pixel17</th>\n      <th>pixel18</th>\n      <th>pixel19</th>\n      <th>pixel20</th>\n      <th>pixel21</th>\n      <th>pixel22</th>\n      <th>pixel23</th>\n      <th>pixel24</th>\n      <th>pixel25</th>\n      <th>pixel26</th>\n      <th>pixel27</th>\n      <th>pixel28</th>\n      <th>pixel29</th>\n      <th>pixel30</th>\n      <th>pixel31</th>\n      <th>pixel32</th>\n      <th>pixel33</th>\n      <th>pixel34</th>\n      <th>pixel35</th>\n      <th>pixel36</th>\n      <th>pixel37</th>\n      <th>pixel38</th>\n      <th>pixel39</th>\n      <th>...</th>\n      <th>pixel745</th>\n      <th>pixel746</th>\n      <th>pixel747</th>\n      <th>pixel748</th>\n      <th>pixel749</th>\n      <th>pixel750</th>\n      <th>pixel751</th>\n      <th>pixel752</th>\n      <th>pixel753</th>\n      <th>pixel754</th>\n      <th>pixel755</th>\n      <th>pixel756</th>\n      <th>pixel757</th>\n      <th>pixel758</th>\n      <th>pixel759</th>\n      <th>pixel760</th>\n      <th>pixel761</th>\n      <th>pixel762</th>\n      <th>pixel763</th>\n      <th>pixel764</th>\n      <th>pixel765</th>\n      <th>pixel766</th>\n      <th>pixel767</th>\n      <th>pixel768</th>\n      <th>pixel769</th>\n      <th>pixel770</th>\n      <th>pixel771</th>\n      <th>pixel772</th>\n      <th>pixel773</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>114</td>\n      <td>183</td>\n      <td>112</td>\n      <td>55</td>\n      <td>23</td>\n      <td>72</td>\n      <td>102</td>\n      <td>165</td>\n      <td>160</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>24</td>\n      <td>188</td>\n      <td>163</td>\n      <td>93</td>\n      <td>...</td>\n      <td>171</td>\n      <td>249</td>\n      <td>207</td>\n      <td>197</td>\n      <td>202</td>\n      <td>45</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22</td>\n      <td>21</td>\n      <td>25</td>\n      <td>69</td>\n      <td>52</td>\n      <td>45</td>\n      <td>74</td>\n      <td>39</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41</td>\n      <td>162</td>\n      <td>167</td>\n      <td>84</td>\n      <td>30</td>\n      <td>38</td>\n      <td>94</td>\n      <td>177</td>\n      <td>176</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>41</td>\n      <td>147</td>\n      <td>228</td>\n      <td>242</td>\n      <td>228</td>\n      <td>...</td>\n      <td>231</td>\n      <td>231</td>\n      <td>228</td>\n      <td>229</td>\n      <td>212</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>101</td>\n      <td>157</td>\n      <td>148</td>\n      <td>148</td>\n      <td>167</td>\n      <td>180</td>\n      <td>182</td>\n      <td>179</td>\n      <td>176</td>\n      <td>172</td>\n      <td>171</td>\n      <td>164</td>\n      <td>177</td>\n      <td>163</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>142</td>\n      <td>205</td>\n      <td>...</td>\n      <td>84</td>\n      <td>240</td>\n      <td>194</td>\n      <td>186</td>\n      <td>181</td>\n      <td>192</td>\n      <td>133</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>15</td>\n      <td>13</td>\n      <td>5</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>122</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28</td>\n      <td>146</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129</td>\n      <td>193</td>\n      <td>122</td>\n      <td>...</td>\n      <td>171</td>\n      <td>176</td>\n      <td>180</td>\n      <td>189</td>\n      <td>193</td>\n      <td>139</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n      <td>133</td>\n      <td>155</td>\n      <td>159</td>\n      <td>157</td>\n      <td>162</td>\n      <td>157</td>\n      <td>161</td>\n      <td>161</td>\n      <td>163</td>\n      <td>151</td>\n      <td>145</td>\n      <td>125</td>\n      <td>93</td>\n      <td>87</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>171</td>\n      <td>252</td>\n      <td>213</td>\n      <td>217</td>\n      <td>217</td>\n      <td>219</td>\n      <td>218</td>\n      <td>217</td>\n      <td>208</td>\n      <td>245</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248</td>\n      <td>255</td>\n      <td>...</td>\n      <td>255</td>\n      <td>146</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>231</td>\n      <td>198</td>\n      <td>0</td>\n      <td>0</td>\n      <td>165</td>\n      <td>244</td>\n      <td>32</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78b247e075f487d6449d75dbefe1b45ceb803ede"
      },
      "cell_type": "code",
      "source": "df.info()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 12000 entries, 3 to 59996\nColumns: 785 entries, label to pixel784\ndtypes: int64(785)\nmemory usage: 72.0 MB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37bcc80e854cd984b88bcadf07865fa42df8efb0"
      },
      "cell_type": "code",
      "source": "# We will split our data\n\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop([\"label\"], axis=1)\nY = df.label\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f005cd4dfc0c97057c286d1177426058019c466d"
      },
      "cell_type": "code",
      "source": "# Example Images\n\nplt.figure(figsize=(8,8))\nfor i in range(4):\n    plt.subplot(2,2,i+1)\n    plt.axis('off')\n    plt.imshow(x_train.head().values[i].reshape(28,28), cmap='gray', interpolation='none')",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 576x576 with 4 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ca4572528683c5e8e41b5972d7e93af4d115a3ab"
      },
      "cell_type": "markdown",
      "source": "**ANN with Keras**<a id=3></a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab079ea2fb6b3b7b1338ebceb760d6a8075ef1c5"
      },
      "cell_type": "code",
      "source": "x_train = x_train.values.T\ny_train = y_train.values.reshape(8400,1).T\nx_test = x_test.values.T\ny_test = y_test.values.reshape(3600,1).T",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e57d82a55fda90e1fb6b2ec778632965cd6a6a02"
      },
      "cell_type": "code",
      "source": "from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\ndef buildClassifier():\n    classifier = Sequential()\n    classifier.add(Dense(units=8, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=x_train.shape[0])) # Hidden Layer 1 with 8 nodes\n    classifier.add(Dense(units=6, kernel_initializer=\"uniform\", activation=\"relu\"))  # Hidden Layer 2 with 6 nodes\n    classifier.add(Dense(units=1, kernel_initializer=\"uniform\", activation=\"sigmoid\")) # Output Layer\n    classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n    return classifier\n\n\nclassifier = KerasClassifier(build_fn=buildClassifier, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = x_train.T, y = y_train.T, cv=3)\nmean = accuracies.mean()\nvariance = accuracies.std()\n\nprint(\"Accuracy Mean is {:.2f}%\".format(mean*100))\nprint(\"Accuracy Variance is {}\".format(variance))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/100\n5600/5600 [==============================] - 1s 127us/step - loss: 0.1261 - acc: 0.9571\nEpoch 2/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0534 - acc: 0.9812\nEpoch 3/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0462 - acc: 0.9841\nEpoch 4/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0411 - acc: 0.9868\nEpoch 5/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0384 - acc: 0.9863\nEpoch 6/100\n5600/5600 [==============================] - 0s 60us/step - loss: 0.0335 - acc: 0.9871\nEpoch 7/100\n5600/5600 [==============================] - 0s 61us/step - loss: 0.0314 - acc: 0.9895\nEpoch 8/100\n5600/5600 [==============================] - 0s 59us/step - loss: 0.0274 - acc: 0.9916\nEpoch 9/100\n5600/5600 [==============================] - 0s 58us/step - loss: 0.0314 - acc: 0.9896\nEpoch 10/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0209 - acc: 0.9927\nEpoch 11/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0224 - acc: 0.9916\nEpoch 12/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0292 - acc: 0.9889\nEpoch 13/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0223 - acc: 0.9916\nEpoch 14/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0200 - acc: 0.9923\nEpoch 15/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0203 - acc: 0.9923\nEpoch 16/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0190 - acc: 0.9921\nEpoch 17/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0149 - acc: 0.9945\nEpoch 18/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0208 - acc: 0.9930\nEpoch 19/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0235 - acc: 0.9918\nEpoch 20/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0094 - acc: 0.9959\nEpoch 21/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0131 - acc: 0.9948\nEpoch 22/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0117 - acc: 0.9955\nEpoch 23/100\n5600/5600 [==============================] - 0s 43us/step - loss: 0.0165 - acc: 0.9941\nEpoch 24/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0127 - acc: 0.9952\nEpoch 25/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0093 - acc: 0.9964\nEpoch 26/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0128 - acc: 0.9948\nEpoch 27/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0111 - acc: 0.9955\nEpoch 28/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0229 - acc: 0.9918\nEpoch 29/100\n5600/5600 [==============================] - 0s 43us/step - loss: 0.0106 - acc: 0.9954\nEpoch 30/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0083 - acc: 0.9970\nEpoch 31/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0092 - acc: 0.9961\nEpoch 32/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0141 - acc: 0.9952\nEpoch 33/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0093 - acc: 0.9966\nEpoch 34/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0097 - acc: 0.9964\nEpoch 35/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0142 - acc: 0.9943\nEpoch 36/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0053 - acc: 0.9968\nEpoch 37/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0098 - acc: 0.9973\nEpoch 38/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0150 - acc: 0.9955\nEpoch 39/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0051 - acc: 0.9982\nEpoch 40/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0054 - acc: 0.9982\nEpoch 41/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0030 - acc: 0.9988\nEpoch 42/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0048 - acc: 0.9971\nEpoch 43/100\n5600/5600 [==============================] - 0s 43us/step - loss: 0.0113 - acc: 0.9961\nEpoch 44/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0086 - acc: 0.9957\nEpoch 45/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0027 - acc: 0.9980\nEpoch 46/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0339 - acc: 0.9848\nEpoch 47/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0226 - acc: 0.9854\nEpoch 48/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0190 - acc: 0.9875\nEpoch 49/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0129 - acc: 0.9888\nEpoch 50/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0104 - acc: 0.9929\nEpoch 51/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0105 - acc: 0.9980\nEpoch 52/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0115 - acc: 0.9970\nEpoch 53/100\n5600/5600 [==============================] - 0s 52us/step - loss: 0.0107 - acc: 0.9982\nEpoch 54/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0232 - acc: 0.9950\nEpoch 55/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0113 - acc: 0.9968\nEpoch 56/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0092 - acc: 0.9982\nEpoch 57/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0099 - acc: 0.9977\nEpoch 58/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0075 - acc: 0.9982\nEpoch 59/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0074 - acc: 0.9986\nEpoch 60/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0054 - acc: 0.9988\nEpoch 61/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0055 - acc: 0.9989\nEpoch 62/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0118 - acc: 0.9968\nEpoch 63/100\n5600/5600 [==============================] - 0s 52us/step - loss: 0.0076 - acc: 0.9979\nEpoch 64/100\n5600/5600 [==============================] - 0s 52us/step - loss: 0.0055 - acc: 0.9989\nEpoch 65/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0045 - acc: 0.9993\nEpoch 66/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0043 - acc: 0.9993\nEpoch 67/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0044 - acc: 0.9993\nEpoch 68/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0090 - acc: 0.9984\nEpoch 69/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0166 - acc: 0.9932\nEpoch 70/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0115 - acc: 0.9964\nEpoch 71/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0054 - acc: 0.9988\nEpoch 72/100\n5600/5600 [==============================] - 0s 52us/step - loss: 0.0046 - acc: 0.9989\nEpoch 73/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0032 - acc: 0.9995\nEpoch 74/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0030 - acc: 0.9995\nEpoch 75/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0081 - acc: 0.9975\nEpoch 76/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0087 - acc: 0.9977\nEpoch 77/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0035 - acc: 0.9995\nEpoch 78/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0033 - acc: 0.9993\nEpoch 79/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0054 - acc: 0.9986\nEpoch 80/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0028 - acc: 0.9995\nEpoch 81/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0028 - acc: 0.9995\nEpoch 82/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0027 - acc: 0.9995\nEpoch 83/100\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "5600/5600 [==============================] - 0s 47us/step - loss: 0.0026 - acc: 0.9995\nEpoch 84/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0025 - acc: 0.9995\nEpoch 85/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0156 - acc: 0.9966\nEpoch 86/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0037 - acc: 0.9991\nEpoch 87/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0026 - acc: 0.9995\nEpoch 88/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0025 - acc: 0.9995\nEpoch 89/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0024 - acc: 0.9995\nEpoch 90/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0024 - acc: 0.9995\nEpoch 91/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0144 - acc: 0.9973\nEpoch 92/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0162 - acc: 0.9959\nEpoch 93/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0064 - acc: 0.9973\nEpoch 94/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0063 - acc: 0.9980\nEpoch 95/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0045 - acc: 0.9988\nEpoch 96/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0040 - acc: 0.9988\nEpoch 97/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0024 - acc: 0.9995\nEpoch 98/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0023 - acc: 0.9995\nEpoch 99/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0024 - acc: 0.9995\nEpoch 100/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0024 - acc: 0.9995\n2800/2800 [==============================] - 0s 54us/step\nEpoch 1/100\n5600/5600 [==============================] - 1s 124us/step - loss: 0.1124 - acc: 0.9654\nEpoch 2/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0437 - acc: 0.9823\nEpoch 3/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0407 - acc: 0.9848\nEpoch 4/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0338 - acc: 0.9886\nEpoch 5/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0319 - acc: 0.9891\nEpoch 6/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0241 - acc: 0.9913\nEpoch 7/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0222 - acc: 0.9929\nEpoch 8/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0211 - acc: 0.9930\nEpoch 9/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0226 - acc: 0.9918\nEpoch 10/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0184 - acc: 0.9941\nEpoch 11/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0202 - acc: 0.9927\nEpoch 12/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0181 - acc: 0.9927\nEpoch 13/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0198 - acc: 0.9925\nEpoch 14/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0204 - acc: 0.9923\nEpoch 15/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0121 - acc: 0.9955\nEpoch 16/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0177 - acc: 0.9930\nEpoch 17/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0152 - acc: 0.9950\nEpoch 18/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0194 - acc: 0.9930\nEpoch 19/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0167 - acc: 0.9952\nEpoch 20/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0091 - acc: 0.9970\nEpoch 21/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0083 - acc: 0.9970\nEpoch 22/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0122 - acc: 0.9941\nEpoch 23/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0080 - acc: 0.9968\nEpoch 24/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0068 - acc: 0.9973\nEpoch 25/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0064 - acc: 0.9977\nEpoch 26/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0172 - acc: 0.9945\nEpoch 27/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0092 - acc: 0.9966\nEpoch 28/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0092 - acc: 0.9961\nEpoch 29/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0065 - acc: 0.9973\nEpoch 30/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0092 - acc: 0.9964\nEpoch 31/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0096 - acc: 0.9962\nEpoch 32/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0084 - acc: 0.9973\nEpoch 33/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0065 - acc: 0.9982\nEpoch 34/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0055 - acc: 0.9984\nEpoch 35/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0049 - acc: 0.9979\nEpoch 36/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0115 - acc: 0.9964\nEpoch 37/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0048 - acc: 0.9979\nEpoch 38/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0100 - acc: 0.9968\nEpoch 39/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0024 - acc: 0.9989\nEpoch 40/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0023 - acc: 0.9988\nEpoch 41/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0019 - acc: 0.9989\nEpoch 42/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0023 - acc: 0.9988\nEpoch 43/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0021 - acc: 0.9988\nEpoch 44/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0015 - acc: 0.9991\nEpoch 45/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0015 - acc: 0.9989\nEpoch 46/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0015 - acc: 0.9989\nEpoch 47/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0014 - acc: 0.9991\nEpoch 48/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0064 - acc: 0.9977\nEpoch 49/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0170 - acc: 0.9939\nEpoch 50/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0092 - acc: 0.9975\nEpoch 51/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0076 - acc: 0.9966\nEpoch 52/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0074 - acc: 0.9970\nEpoch 53/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0063 - acc: 0.9973\nEpoch 54/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0035 - acc: 0.9984\nEpoch 55/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0018 - acc: 0.9989\nEpoch 56/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0112 - acc: 0.9962\nEpoch 57/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0126 - acc: 0.9952\nEpoch 58/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0053 - acc: 0.9980\nEpoch 59/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0030 - acc: 0.9988\nEpoch 60/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0032 - acc: 0.9988\nEpoch 61/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0091 - acc: 0.9968\nEpoch 62/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0032 - acc: 0.9988\nEpoch 63/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0046 - acc: 0.9984\nEpoch 64/100\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "5600/5600 [==============================] - 0s 47us/step - loss: 0.0026 - acc: 0.9988\nEpoch 65/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0015 - acc: 0.9993\nEpoch 66/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0033 - acc: 0.9982\nEpoch 67/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0141 - acc: 0.9950\nEpoch 68/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0034 - acc: 0.9984\nEpoch 69/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0038 - acc: 0.9984\nEpoch 70/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0021 - acc: 0.9989\nEpoch 71/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0026 - acc: 0.9986\nEpoch 72/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0015 - acc: 0.9991\nEpoch 73/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0011 - acc: 0.9991\nEpoch 74/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0011 - acc: 0.9993\nEpoch 75/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0040 - acc: 0.9984\nEpoch 76/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0028 - acc: 0.9986\nEpoch 77/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0058 - acc: 0.9982\nEpoch 78/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0030 - acc: 0.9988\nEpoch 79/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0147 - acc: 0.9961\nEpoch 80/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0058 - acc: 0.9982\nEpoch 81/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0035 - acc: 0.9980\nEpoch 82/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0023 - acc: 0.9989\nEpoch 83/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0025 - acc: 0.9988\nEpoch 84/100\n5600/5600 [==============================] - 0s 45us/step - loss: 6.3361e-04 - acc: 0.9995\nEpoch 85/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0046 - acc: 0.9982\nEpoch 86/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0027 - acc: 0.9988\nEpoch 87/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0126 - acc: 0.9966\nEpoch 88/100\n5600/5600 [==============================] - 0s 44us/step - loss: 0.0021 - acc: 0.9989\nEpoch 89/100\n5600/5600 [==============================] - 0s 45us/step - loss: 9.9522e-04 - acc: 0.9995\nEpoch 90/100\n5600/5600 [==============================] - 0s 45us/step - loss: 7.5599e-04 - acc: 0.9995\nEpoch 91/100\n5600/5600 [==============================] - 0s 50us/step - loss: 6.3645e-04 - acc: 0.9995\nEpoch 92/100\n5600/5600 [==============================] - 0s 45us/step - loss: 5.4229e-04 - acc: 0.9995\nEpoch 93/100\n5600/5600 [==============================] - 0s 47us/step - loss: 4.9193e-04 - acc: 0.9995\nEpoch 94/100\n5600/5600 [==============================] - 0s 47us/step - loss: 4.6516e-04 - acc: 0.9995\nEpoch 95/100\n5600/5600 [==============================] - 0s 46us/step - loss: 4.4648e-04 - acc: 0.9995\nEpoch 96/100\n5600/5600 [==============================] - 0s 45us/step - loss: 4.3313e-04 - acc: 0.9995\nEpoch 97/100\n5600/5600 [==============================] - 0s 46us/step - loss: 4.2222e-04 - acc: 0.9995\nEpoch 98/100\n5600/5600 [==============================] - 0s 45us/step - loss: 4.1194e-04 - acc: 0.9995\nEpoch 99/100\n5600/5600 [==============================] - 0s 46us/step - loss: 4.0341e-04 - acc: 0.9995\nEpoch 100/100\n5600/5600 [==============================] - 0s 44us/step - loss: 3.9419e-04 - acc: 0.9995\n2800/2800 [==============================] - 0s 61us/step\nEpoch 1/100\n5600/5600 [==============================] - 1s 134us/step - loss: 0.2026 - acc: 0.9218\nEpoch 2/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0472 - acc: 0.9836\nEpoch 3/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0457 - acc: 0.9839\nEpoch 4/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0383 - acc: 0.9855\nEpoch 5/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0316 - acc: 0.9889\nEpoch 6/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0325 - acc: 0.9879\nEpoch 7/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0263 - acc: 0.9891\nEpoch 8/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0326 - acc: 0.9868\nEpoch 9/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0217 - acc: 0.9920\nEpoch 10/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0220 - acc: 0.9921\nEpoch 11/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0201 - acc: 0.9929\nEpoch 12/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0191 - acc: 0.9932\nEpoch 13/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0177 - acc: 0.9929\nEpoch 14/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0186 - acc: 0.9930\nEpoch 15/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0160 - acc: 0.9939\nEpoch 16/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0129 - acc: 0.9955\nEpoch 17/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0181 - acc: 0.9936\nEpoch 18/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0152 - acc: 0.9954\nEpoch 19/100\n5600/5600 [==============================] - 0s 45us/step - loss: 0.0092 - acc: 0.9973\nEpoch 20/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0110 - acc: 0.9954\nEpoch 21/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0100 - acc: 0.9968\nEpoch 22/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0053 - acc: 0.9980\nEpoch 23/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0106 - acc: 0.9962\nEpoch 24/100\n5600/5600 [==============================] - 0s 46us/step - loss: 0.0068 - acc: 0.9977\nEpoch 25/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0096 - acc: 0.9959\nEpoch 26/100\n5600/5600 [==============================] - 0s 48us/step - loss: 0.0146 - acc: 0.9941\nEpoch 27/100\n5600/5600 [==============================] - 0s 50us/step - loss: 0.0117 - acc: 0.9957\nEpoch 28/100\n5600/5600 [==============================] - 0s 47us/step - loss: 0.0105 - acc: 0.9964\nEpoch 29/100\n5600/5600 [==============================] - 0s 49us/step - loss: 0.0056 - acc: 0.9975\nEpoch 30/100\n5600/5600 [==============================] - 0s 54us/step - loss: 0.0047 - acc: 0.9982\nEpoch 31/100\n5600/5600 [==============================] - 0s 51us/step - loss: 0.0149 - acc: 0.9939\nEpoch 32/100\n5600/5600 [==============================] - 0s 52us/step - loss: 0.0076 - acc: 0.9970\nEpoch 33/100\n5600/5600 [==============================] - 0s 54us/step - loss: 0.0044 - acc: 0.9982\nEpoch 34/100\n5600/5600 [==============================] - 0s 58us/step - loss: 0.0019 - acc: 0.9993\nEpoch 35/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0040 - acc: 0.9988\nEpoch 36/100\n5600/5600 [==============================] - 0s 59us/step - loss: 0.0220 - acc: 0.9948\nEpoch 37/100\n5600/5600 [==============================] - 0s 55us/step - loss: 0.0140 - acc: 0.9941\nEpoch 38/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0075 - acc: 0.9970\nEpoch 39/100\n5600/5600 [==============================] - 0s 55us/step - loss: 0.0049 - acc: 0.9986\nEpoch 40/100\n5600/5600 [==============================] - 0s 54us/step - loss: 0.0022 - acc: 0.9989\nEpoch 41/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0048 - acc: 0.9988\nEpoch 42/100\n5600/5600 [==============================] - 0s 56us/step - loss: 0.0093 - acc: 0.9966\nEpoch 43/100\n5600/5600 [==============================] - 0s 60us/step - loss: 0.0038 - acc: 0.9989\nEpoch 44/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0016 - acc: 0.9996\nEpoch 45/100\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "5600/5600 [==============================] - 0s 52us/step - loss: 0.0091 - acc: 0.9962\nEpoch 46/100\n5600/5600 [==============================] - 0s 53us/step - loss: 0.0021 - acc: 0.9995\nEpoch 47/100\n5600/5600 [==============================] - 0s 55us/step - loss: 0.0031 - acc: 0.9991\nEpoch 48/100\n5600/5600 [==============================] - 0s 58us/step - loss: 6.8306e-04 - acc: 0.9998\nEpoch 49/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0019 - acc: 0.9996\nEpoch 50/100\n5600/5600 [==============================] - 0s 57us/step - loss: 0.0010 - acc: 0.9998\nEpoch 51/100\n5600/5600 [==============================] - 0s 56us/step - loss: 0.0070 - acc: 0.9971\nEpoch 52/100\n5600/5600 [==============================] - 0s 55us/step - loss: 5.4300e-04 - acc: 1.0000\nEpoch 53/100\n5600/5600 [==============================] - 0s 56us/step - loss: 3.4355e-04 - acc: 1.0000\nEpoch 54/100\n5600/5600 [==============================] - 0s 55us/step - loss: 2.7773e-04 - acc: 1.0000\nEpoch 55/100\n5600/5600 [==============================] - 0s 54us/step - loss: 2.1845e-04 - acc: 1.0000\nEpoch 56/100\n5600/5600 [==============================] - 0s 53us/step - loss: 1.8711e-04 - acc: 1.0000\nEpoch 57/100\n5600/5600 [==============================] - 0s 55us/step - loss: 1.7280e-04 - acc: 1.0000\nEpoch 58/100\n5600/5600 [==============================] - 0s 53us/step - loss: 1.5216e-04 - acc: 1.0000\nEpoch 59/100\n5600/5600 [==============================] - 0s 54us/step - loss: 1.4954e-04 - acc: 1.0000\nEpoch 60/100\n5600/5600 [==============================] - 0s 60us/step - loss: 1.3480e-04 - acc: 1.0000\nEpoch 61/100\n5600/5600 [==============================] - 0s 59us/step - loss: 1.2653e-04 - acc: 1.0000\nEpoch 62/100\n5600/5600 [==============================] - 0s 56us/step - loss: 1.1453e-04 - acc: 1.0000\nEpoch 63/100\n5600/5600 [==============================] - 0s 48us/step - loss: 1.0568e-04 - acc: 1.0000\nEpoch 64/100\n5600/5600 [==============================] - 0s 52us/step - loss: 1.0247e-04 - acc: 1.0000\nEpoch 65/100\n5600/5600 [==============================] - 0s 64us/step - loss: 9.9977e-05 - acc: 1.0000\nEpoch 66/100\n5600/5600 [==============================] - 0s 65us/step - loss: 9.7851e-05 - acc: 1.0000\nEpoch 67/100\n5600/5600 [==============================] - 0s 57us/step - loss: 1.4496e-04 - acc: 1.0000\nEpoch 68/100\n5600/5600 [==============================] - 0s 56us/step - loss: 1.0999e-04 - acc: 1.0000\nEpoch 69/100\n5600/5600 [==============================] - 0s 54us/step - loss: 9.4551e-05 - acc: 1.0000\nEpoch 70/100\n5600/5600 [==============================] - 0s 56us/step - loss: 9.1887e-05 - acc: 1.0000\nEpoch 71/100\n5600/5600 [==============================] - 0s 57us/step - loss: 8.9751e-05 - acc: 1.0000\nEpoch 72/100\n5600/5600 [==============================] - 0s 53us/step - loss: 8.7814e-05 - acc: 1.0000\nEpoch 73/100\n5600/5600 [==============================] - 0s 55us/step - loss: 8.6029e-05 - acc: 1.0000\nEpoch 74/100\n5600/5600 [==============================] - 0s 57us/step - loss: 8.4248e-05 - acc: 1.0000\nEpoch 75/100\n5600/5600 [==============================] - 0s 54us/step - loss: 8.2469e-05 - acc: 1.0000\nEpoch 76/100\n5600/5600 [==============================] - 0s 58us/step - loss: 8.0752e-05 - acc: 1.0000\nEpoch 77/100\n5600/5600 [==============================] - 0s 62us/step - loss: 7.8986e-05 - acc: 1.0000\nEpoch 78/100\n5600/5600 [==============================] - 0s 56us/step - loss: 7.7275e-05 - acc: 1.0000\nEpoch 79/100\n5600/5600 [==============================] - 0s 54us/step - loss: 7.5559e-05 - acc: 1.0000\nEpoch 80/100\n5600/5600 [==============================] - 0s 53us/step - loss: 7.3830e-05 - acc: 1.0000\nEpoch 81/100\n5600/5600 [==============================] - 0s 53us/step - loss: 7.2151e-05 - acc: 1.0000\nEpoch 82/100\n5600/5600 [==============================] - 0s 47us/step - loss: 7.0484e-05 - acc: 1.0000\nEpoch 83/100\n5600/5600 [==============================] - 0s 46us/step - loss: 6.8726e-05 - acc: 1.0000\nEpoch 84/100\n5600/5600 [==============================] - 0s 49us/step - loss: 6.7041e-05 - acc: 1.0000\nEpoch 85/100\n5600/5600 [==============================] - 0s 47us/step - loss: 6.5363e-05 - acc: 1.0000\nEpoch 86/100\n5600/5600 [==============================] - 0s 47us/step - loss: 6.3666e-05 - acc: 1.0000\nEpoch 87/100\n5600/5600 [==============================] - 0s 45us/step - loss: 6.2060e-05 - acc: 1.0000\nEpoch 88/100\n5600/5600 [==============================] - 0s 46us/step - loss: 6.0405e-05 - acc: 1.0000\nEpoch 89/100\n5600/5600 [==============================] - 0s 46us/step - loss: 5.8834e-05 - acc: 1.0000\nEpoch 90/100\n5600/5600 [==============================] - 0s 46us/step - loss: 5.7154e-05 - acc: 1.0000\nEpoch 91/100\n5600/5600 [==============================] - 0s 47us/step - loss: 5.5522e-05 - acc: 1.0000\nEpoch 92/100\n5600/5600 [==============================] - 0s 46us/step - loss: 5.3944e-05 - acc: 1.0000\nEpoch 93/100\n5600/5600 [==============================] - 0s 48us/step - loss: 5.2393e-05 - acc: 1.0000\nEpoch 94/100\n5600/5600 [==============================] - 0s 46us/step - loss: 5.0840e-05 - acc: 1.0000\nEpoch 95/100\n5600/5600 [==============================] - 0s 45us/step - loss: 4.9364e-05 - acc: 1.0000\nEpoch 96/100\n5600/5600 [==============================] - 0s 47us/step - loss: 4.7910e-05 - acc: 1.0000\nEpoch 97/100\n5600/5600 [==============================] - 0s 48us/step - loss: 4.6376e-05 - acc: 1.0000\nEpoch 98/100\n5600/5600 [==============================] - 0s 47us/step - loss: 4.4902e-05 - acc: 1.0000\nEpoch 99/100\n5600/5600 [==============================] - 0s 48us/step - loss: 4.3426e-05 - acc: 1.0000\nEpoch 100/100\n5600/5600 [==============================] - 0s 45us/step - loss: 4.2012e-05 - acc: 1.0000\n2800/2800 [==============================] - 0s 68us/step\nAccuracy Mean is 99.08%\nAccuracy Variance is 0.0014384578539993634\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e34edab4f7630979b8066240cdb8820ec49184f"
      },
      "cell_type": "markdown",
      "source": "**We can say our model works with  approximately <font color=\"red\">99%</font> of acuracy.**"
    },
    {
      "metadata": {
        "_uuid": "e60a25a598358170cb2fc644ed5960139bae8c3e"
      },
      "cell_type": "markdown",
      "source": "Thanks for your time!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
